services:
  mysql:
    image: mysql:8.0
    # platform: linux/amd64
    container_name: family-tree-mysql
    ports:
      - "3306:3306"
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    volumes:
      - mysql-data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: family-tree-redis
    ports:
      - "6379:6379"
    environment:
      - TZ=Asia/Ho_Chi_Minh
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 1s
      timeout: 3s
      retries: 5

  backend:
    build:
      context: ../apps/backend
      dockerfile: Dockerfile
    container_name: family-tree-backend
    ports:
      - "8080:8080"
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
      - Hangfire__RedisConnectionString=redis:6379
    depends_on:
      - mysql
      - redis
      - rabbitmq
    volumes:
      - backend-dataprotection-keys:/root/.aspnet/DataProtection-Keys
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - local-uploads:/app/uploads

    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  admin:
    build:
      context: ../apps/admin
      dockerfile: Dockerfile
    container_name: family-tree-admin
    ports:
      - "8081:80"
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    depends_on:
      - backend
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  face-service:
    build:
      context: ../services/face-service
      dockerfile: Dockerfile
    container_name: family-tree-face-service
    ports:
      - "8000:8000" # Expose port 8000 for the FastAPI app
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    mem_limit: 4g # Increase memory limit
    volumes:
      - ../infra/app/models:/face-service/app/models/dlib_models
      - ../infra/app/models:/face-service/app/models/onnx_models
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  ocr-service:
    build:
      context: ../services/ocr-service
      dockerfile: Dockerfile
    container_name: family-tree-ocr-service
    ports:
      - "8001:8000" # Expose port 8000 for the FastAPI app
    env_file:
      - ./.env.dev
    environment:
      - PYTHONUNBUFFERED=1 # Ensure Python output is unbuffered
      - TZ=Asia/Ho_Chi_Minh
    mem_limit: 2g # Set memory limit for OCR service
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  notification-service:
    build:
      context: ../services/notification-service
      dockerfile: Dockerfile
    container_name: family-tree-notification-service
    ports:
      - "3000:3000" # Expose port 3000 for the Node.js app
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  knowledge-search-service:
    build:
      context: ../services/knowledge-search-service
      dockerfile: Dockerfile
    container_name: family-tree-knowledge-search-service
    ports:
      - "8002:8000" # Expose port 8000 for the FastAPI app internally, map to 8002 externally
    env_file:
      - ./.env.dev
    environment:
      - PYTHONUNBUFFERED=1 # Ensure Python output is unbuffered
      - TZ=Asia/Ho_Chi_Minh
    mem_limit: 2g # Set memory limit for knowledge search service
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  llm-gateway-service:
    build:
      context: ../services/llm-gateway-service
      dockerfile: Dockerfile
    container_name: family-tree-llm-gateway-service
    ports:
      - "8004:8000" # Expose port 8000 for the FastAPI app internally, map to 8004 externally
    env_file:
      - ./.env.dev
    environment:
      - PYTHONUNBUFFERED=1 # Ensure Python output is unbuffered
      - TZ=Asia/Ho_Chi_Minh
    mem_limit: 2g # Set memory limit for LLM Gateway service
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: family-tree-rabbitmq
    ports:
      - "5672:5672" # AMQP protocol port
      - "15672:15672" # Management UI port
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  storage-service:
    build:
      context: ../services/storage-service
      dockerfile: Dockerfile
    container_name: family-tree-storage-service
    ports:
      - "8003:8000" # Expose port 8000 for the Node.js app
    env_file:
      - ./.env.dev
    environment:
      - TZ=Asia/Ho_Chi_Minh
    volumes:
      - local-uploads:/app/uploads # Mount shared volume
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  mysql-data:
  backend-dataprotection-keys:
  redis-data:
  rabbitmq-data:
  local-uploads:
